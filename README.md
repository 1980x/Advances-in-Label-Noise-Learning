# Learning-with-Noisy-Labels

    A curated list of resources for Learning with Noisy Labels and a few relevant papers about Weakly/Self Supervised Learning

---

- Content
  - [Papers & Code (2021)](#papers--code (2021))
  - [Papers & Code (2020)](#papers--code (2020))
---

## Papers & Code (2021)

This repo focus on papers after 2019, for previous works, please refer to (https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise).

### International Conference on Learning Representations (ICLR 2021)
Conference date: May 3, 2021 -- May 7, 2021

* When Optimizing -Divergence is Robust with Label Noise. [[Paper]](https://openreview.net/pdf?id=WesiCoRVQ15)[[Code]](https://github.com/weijiaheng/Robust-f-divergence-measures) 
* Learning with Instance-Dependent Label Noise: A Sample Sieve Approach. [[Paper]](https://openreview.net/pdf?id=2VXyy9mIyU3)[[Code]](https://github.com/haochenglouis/cores) 
* Noise against noise: stochastic label noise helps combat inherent label noise. [[Paper]](https://openreview.net/pdf?id=80FMcTSZ6J0)[[Code]](https://github.com/chenpf1025/SLN)
* Learning with Feature-Dependent Label Noise: A Progressive Approach. [[Paper]](https://openreview.net/pdf?id=ZPa2SyGcbwh)[[Code]](https://github.com/pxiangwu/PLC)
* Robust early-learning: Hindering the memorization of noisy labels. [[Paper]](https://openreview.net/pdf?id=Eql5b1_hTE4)[[Code]](https://github.com/xiaoboxia/CDR)
* Robust Curriculum Learning: from clean label detection to noisy label self-correction. [[Paper]](https://openreview.net/pdf?id=lmTWnm3coJJ)
* How Does Mixup Help With Robustness and Generalization? [[Paper]](https://openreview.net/pdf?id=8yKEo06dKNo)
* Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. [[Paper]](https://openreview.net/pdf?id=rC8sJ4i6kaH)
-----
### IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2021) -- Updating
Conference date: Jun 19, 2021 -- Jun 25, 2021

* A Second-Order Approach to Learning with Instance-Dependent Label Noise. [[Paper]](https://arxiv.org/abs/2012.11854)[[Code]](https://github.com/UCSC-REAL/CAL)
* Improving Unsupervised Image Clustering With Robust Learning. [[Paper]](https://arxiv.org/abs/2012.11150)
* Multi-Objective Interpolation Training for Robustness to Label Noise. [[Paper]](https://arxiv.org/abs/2012.04462)[[Code]](https://git.io/JI40X)
* Noise-resistant Deep Metric Learning with Ranking-based Instance Selection. [[Paper]](https://arxiv.org/abs/2103.16047)[[Code]](https://github.com/alibaba-edu/Ranking-based-Instance-Selection)
* Augmentation Strategies for Learning with Noisy Labels. [[Paper]](https://arxiv.org/abs/2103.02130)[[Code]](https://github.com/KentoNishi/Augmentation-for-LNL)
* Jo-SRC: A Contrastive Approach for Combating Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.13029.pdf)[[Code]](https://github.com/NUST-Machine-Intelligence-Laboratory/Jo-SRC)
-----
### Artificial Intelligence and Statistics (AISTATS 2021)
Conference date: Apr 13, 2021 -- Apr 15, 2021

* Collaborative Classification from Noisy Labels. [[Paper]](http://proceedings.mlr.press/v130/maystre21a.html)
* Linear Models are Robust Optimal Under Strategic Behavior. [[Paper]](http://proceedings.mlr.press/v130/tang21a.html)
-----
### AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI 2021)
* Beyond Class-Conditional Assumption: A Primary Attempt to Combat Instance-Dependent Label Noise. [[Paper]](https://arxiv.org/abs/2012.05458)[[Code]](https://github.com/chenpf1025/IDN)
* Learning to Purify Noisy Labels via Meta Soft Label Corrector. [[Paper]](https://arxiv.org/abs/2008.00627)[[Code]](https://github.com/WuYichen-97/Learning-to-Purify-Noisy-Labels-via-Meta-Soft-Label-Corrector)
* Robustness of Accuracy Metric and its Inspirations in Learning with Noisy Labels. [[Paper]](https://arxiv.org/abs/2012.04193)[[Code]](https://github.com/chenpf1025/RobustnessAccuracy)
* Learning from Noisy Labels with Complementary Loss Functions. [[Paper]](http://palm.seu.edu.cn/zhangml/files/AAAI'21a.pdf)[[Code]](https://github.com/dengbaowang/CompLossForNoisyLabels)
* Analysing the Noise Model Error for Realistic Noisy Label Data. [[Paper]](https://arxiv.org/abs/2101.09763)[[Code]](https://github.com/uds-lsv/noise-estimation)
* Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model. [[Paper]](https://niug1984.github.io/paper/wang_aaai21.pdf)
* Learning with Group Noise. [[Paper]](https://gcatnjust.github.io/ChenGong/paper/wang_aaai21_2.pdf)
* Meta Label Correction for Noisy Label Learning. [[Paper]](https://www.microsoft.com/en-us/research/publication/meta-label-correction-for-noisy-label-learning/)
-----
### ArXiv 2021
* The importance of understanding instance-level noisy labels. [[Paper]](https://arxiv.org/pdf/2102.05336.pdf)
* Clusterability as an Alternative to Anchor Points When Learning with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2102.05291.pdf)[[Code]](https://github.com/zwzhu-d/HOC)
* A Survey of Label-noise Representation Learning: Past, Present and Future. [[Paper]](https://arxiv.org/pdf/2011.04406.pdf)
* Learning Noise Transition Matrix from Only Noisy Labels via Total Variation Regularization. [[Paper]](https://arxiv.org/pdf/2102.02414.pdf)[[Code]](https://github.com/YivanZhang/lio)
* Noisy-Labeled NER with Confidence Estimation. [[Paper]](https://arxiv.org/pdf/2104.04318.pdf)[[Code]](https://github.com/liukun95/Noisy-NER-Confidence-Estimation)
* Study Group Learning: Improving Retinal Vessel Segmentation Trained with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.03451.pdf)[[Code]](https://github.com/SHI-Labs/SGL-Retinal-Vessel-Segmentation)
* Contrast to Divide: Self-Supervised Pre-Training for Learning with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.13646.pdf)[[Code]](https://github.com/ContrastToDivide/C2D)
* Exponentiated Gradient Reweighting for Robust Training Under Label Noise and Beyond. [[Paper]](https://arxiv.org/pdf/2104.01493.pdf)
* Understanding the Interaction of Adversarial Training with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2102.03482.pdf)
* Learning from Noisy Labels via Dynamic Loss Thresholding. [[Paper]](https://arxiv.org/pdf/2104.02570.pdf)
* Evaluating Multi-label Classifiers with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2102.08427.pdf)
* Self-Supervised Noisy Label Learning for Source-Free Unsupervised Domain Adaptation. [[Paper]](https://arxiv.org/pdf/2102.11614.pdf)
* Transform consistency for learning with noisy labels. [[Paper]](https://arxiv.org/pdf/2103.13872.pdf)
* Learning to Combat Noisy Labels via Classification Margins. [[Paper]](https://arxiv.org/pdf/2102.00751.pdf)
* Robust Classification from Noisy Labels: Integrating Additional Knowledge for Chest
Radiography Abnormality Assessment. [[Paper]](https://arxiv.org/pdf/2104.05261.pdf)
* DST: Data Selection and joint Training for Learning with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.00813.pdf)
* LongReMix: Robust Learning with High Confidence Samples in a Noisy Label Environment. [[Paper]](https://arxiv.org/pdf/2103.04173.pdf)
* A Novel Perspective for Positive-Unlabeled Learning via Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.04685.pdf)
*  Ensemble Learning with Manifold-Based Data Splitting for Noisy Label Correction. [[Paper]](https://arxiv.org/pdf/2103.07641.pdf)
* MetaLabelNet: Learning to Generate Soft-Labels from Noisy-Labels. [[Paper]](https://arxiv.org/pdf/2103.10869.pdf)
* On the Robustness of Monte Carlo Dropout Trained with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.12002.pdf)
*  Co-matching: Combating Noisy Labels by Augmentation Anchoring. [[Paper]](https://arxiv.org/pdf/2103.12814.pdf)
* Pathological Image Segmentation with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2104.02602.pdf)
* CrowdTeacher: Robust Co-teaching with Noisy Answers & Sample-specific Perturbations for Tabular Data. [[Paper]](https://arxiv.org/pdf/2103.17144.pdf)
* Friends and Foes in Learning from Noisy Labels. [[Paper]](https://arxiv.org/pdf/2103.15055.pdf)
-----
## Papers & Code (2020--TODO)
-----
### International Conference on Machine Learning (ICML 2020)
* Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates. [[Paper]](http://proceedings.mlr.press/v119/liu20e)[[Code 1]](https://github.com/weijiaheng/Multi-class-Peer-Loss-functions) [[Code 2]](https://github.com/gohsyi/PeerLoss)
* Normalized Loss Functions for Deep Learning with Noisy Labels. [[Paper]](https://arxiv.org/abs/2006.13554)[[Code]](https://github.com/HanxunH/Active-Passive-Losses)
* SIGUA: Forgetting May Make Learning with Noisy Labels More Robust. [[Paper]](http://proceedings.mlr.press/v119/han20c.html)[[Code]](https://github.com/bhanML/SIGUA)
* Error-Bounded Correction of Noisy Labels. [[Paper]](http://proceedings.mlr.press/v119/zheng20c.html)[[Code]](https://github.com/pingqingsheng/LRT)
* Training Binary Neural Networks through Learning with Noisy Supervision. [[Paper]](http://proceedings.mlr.press/v119/han20d.html)[[Code]](https://github.com/zhaohui-yang/Binary-Neural-Networks)
* Improving generalization by controlling label-noise information in neural network weights. [[Paper]](http://proceedings.mlr.press/v119/harutyunyan20a.html)[[Code]](https://github.com/hrayrhar/limit-label-memorization)
* Self-PU: Self Boosted and Calibrated Positive-Unlabeled Training. [[Paper]](https://arxiv.org/abs/2006.11280)[[Code]](https://github.com/VITA-Group/Self-PU)
* Searching to Exploit Memorization Effect in Learning with Noisy Labels. [[Paper]](http://proceedings.mlr.press/v119/yao20b.html)[[Code]](https://github.com/jerermyyoung/rtlearning)
* Learning with Bounded Instance and Label-dependent Label Noise. [[Paper]](http://proceedings.mlr.press/v119/cheng20c.html)
* Label-Noise Robust Domain Adaptation. [[Paper]](http://proceedings.mlr.press/v119/yu20c.html)
* Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels. [[Paper]](http://proceedings.mlr.press/v119/jiang20c)
* Does label smoothing mitigate label noise?. [[Paper]](http://proceedings.mlr.press/v119/lukasik20a.html)
* Learning with Multiple Complementary Labels. [[Paper]](http://proceedings.mlr.press/v119/feng20a.html)
* Deep k-NN for Noisy Labels. [[Paper]](http://proceedings.mlr.press/v119/bahri20a.html)
* Extreme Multi-label Classification from Aggregated Labels. [[Paper]](http://proceedings.mlr.press/v119/shen20f.html)
-----
### ArXiv 2020
* No Regret Sample Selection with Noisy Labels. [[Paper]](https://arxiv.org/pdf/2003.03179.pdf)[[Code]](https://github.com/songheony/TAkS)
* Meta Soft Label Generation for Noisy Labels. [[Paper]](https://arxiv.org/pdf/2007.05836.pdf)[[Code]](https://github.com/gorkemalgan/MSLG_noisy_label)
* Learning from Noisy Labels with Deep Neural Networks: A Survey. [[Paper]](https://arxiv.org/pdf/2007.08199.pdf)
* RAR-U-Net: a Residual Encoder to Attention Decoder by Residual Connections Framework for Spine Segmentation under Noisy Labels. [[Paper]](https://arxiv.org/pdf/2009.12873.pdf)
* Learning from Small Amount of Medical Data with Noisy Labels: A Meta-Learning Approach. [[Paper]](https://arxiv.org/pdf/2010.06939.pdf)
-----
